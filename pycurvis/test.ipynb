{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "from data.data import SphericalDataset, SphericalBlockDataset, stand_norm\n",
    "from data.vis_io import get_mesh\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from cfg.configs import Config\n",
    "from util.utils import count_parameters\n",
    "from train_block import resume_checkpoint_block, load_checkpoint_block\n",
    "from test_block import reconstruct_blocks\n",
    "from network.network import MLP\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "nncfg = Config(\"nn_block_half.yaml\")\n",
    "nncfg = Config(\"nn_single_block.yaml\")\n",
    "testcfg = Config(\"nntest_block_half.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nncfg.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 5])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[..,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming inputs\n",
      "transforming targets\n",
      "creating train test splits for inputs\n",
      "creating train test splits for targets\n"
     ]
    }
   ],
   "source": [
    "grid_dataset = SphericalBlockDataset(**nncfg.get_dataset_param())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 72471.78it/s]\n"
     ]
    }
   ],
   "source": [
    "num_block = len(grid_dataset)\n",
    "comps = []\n",
    "for bi in tqdm(range(num_block)):\n",
    "  phys = grid_dataset.curvs[bi][0]\n",
    "  phys_trans = grid_dataset.curvs[bi][1]\n",
    "  comp = grid_dataset.carts[bi][0]\n",
    "  comp_trans = grid_dataset.carts[bi][1]\n",
    "  comps.append(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([201, 360, 160, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dataset.curv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1xdim, b1ydim, b1zdim = grid_dataset.block_indices[0]\n",
    "curv_b1 = grid_dataset.curv[b1xdim[0]:b1xdim[1], b1ydim[0]:b1ydim[1], b1zdim[0]:b1zdim[1]]\n",
    "cart_b1 = grid_dataset.cart[b1xdim[0]:b1xdim[1], b1ydim[0]:b1ydim[1], b1zdim[0]:b1zdim[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 180, 80, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curv_b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 180, 80, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "earth_nopole_block = np.concatenate([curv_b1, cart_b1], axis=-1)\n",
    "np.save(\"data/earth_nopole_block.npy\", earth_nopole_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 180, 80, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps[7].reshape(100, 180, 80, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = torch.load(\"eval/phys2comp_eval.pk\")\n",
    "comp_preds = eval_data['comp_preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = grid_dataset.curv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11577600, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.reshape(-1, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 34560000 into shape (201,360,160,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a6adeb2a61ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomp_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 34560000 into shape (201,360,160,3)"
     ]
    }
   ],
   "source": [
    "comp_pred = np.concatenate(comp_preds, axis=0).reshape(comp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11520000, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(comp_preds, axis=0).shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d82c3ef9a9c52ca48f89a57a471345d340895240528db2b7c56159ebd2138f11"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('vis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
